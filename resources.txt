Idee Struktur:

~(Ganz kurz) Was sind Hardware Beschleuniger. Custom Designed ASICs. Aktuelles Thema, viel Forschung.
~Was machen HW Beschleuniger im Bereich NN anders im Vergleich zu "normaler" Hardware bspw. guter Durchsatz 8-bit Arithmetik, optimisierte Speichernutzung, ...
~(GPUs 채hnlichkeiten zu HW Beschleunigern f체r Neuronale Netze -> HW Beschleuniger bis zu Faktor 10 schneller)
~Vergleich:
	- Google TPU Tensor Processing Units, Edge TPU -> gedacht f체r Edge Computing
		-> auf Tensorflow Software eingehen (obwohl nicht genaues Thema), da speziell f체r Tensorflow gemacht.
	- Amazon, Intel, IBM
	- andere Typen?
~Outlook, neuere Methoden usw.



Wichtige Paper:
o1~ History FPGAS: https://arxiv.org/pdf/1602.04283.pdf
o2~ Comparison Hardware Accelerators: https://www.mdpi.com/1999-5903/12/7/113/pdf
o3~ Performance analysis Google TPU: https://dl.acm.org/doi/pdf/10.1145/3079856.3080246
o4~ Microsoft FPGAS: https://web.eic.nctu.edu.tw/lpsoc/courses/MS2017Spring/supplemental/15%20DCNN%20hardware.pdf
o5~ Comparison GPUS, CPUS, ASICs and FPGA: https://ieeexplore.ieee.org/document/7577314/)
o6~ Survey GPU, CPU, ASICs, TPU: https://www.researchgate.net/publication/334647302_A_Survey_on_Specialised_Hardware_for_Machine_Learning
o7~ Percentage Usage All Categories: https://link.springer.com/article/10.1007/s11227-020-03325-8
o8~ Other: https://scholar.google.com/scholar?hl=de&as_sdt=0,5&q=hardware+design+for+machine+learning

[
Wie wird HW schneller:
7-Limited Numerical Precision: http://proceedings.mlr.press/v37/gupta15.pdf
8-In-Memory Computation: https://arxiv.org/pdf/1706.00511.pdf
9-Efficient Processing of Deep Neural Networks: https://ieeexplore.ieee.org/document/8114708
]

General:
o11- Difference AI: https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks
o12- FPGAs ALL stuff: https://arxiv.org/pdf/1712.08934.pdf
o13- Performance 760 GOP/s https://www.researchgate.net/publication/333158297_High-Performance_FPGA-Based_CNN_Accelerator_With_Block-Floating-Point_Arithmetic
o14- Rise of Neural Networks Computer Power: Aggarwal, Charu C. "Neural networks and deep learning." Springer 10 (2018): 978-3. P.7
o15- TPU v3 Stats on Google: 420 Teraflops,  https://arxiv.org/pdf/1907.10701.pdf, https://cloud.google.com/tpu/docs/system-architecture
o16- Alpha Go used TPU: https://www.nature.com/articles/nature24270?sf123103138=1
o17- Design HW Accelerator: https://www.cs.utah.edu/~rajeev/pubs/ali-thesis.pdf
o18- Google Summary: https://www.heise.de/newsticker/meldung/Kuenstliche-Intelligenz-Architektur-und-Performance-von-Googles-KI-Chip-TPU-3676312.html
o19- Training AI used NVIDIA: https://www.forbes.com/sites/moorinsights/2017/03/03/a-machine-learning-landscape-where-amd-intel-nvidia-qualcomm-and-xilinx-ai-engines-live/?sh=51f4c788742f
o20- Most used GPU for Training: https://www.wired.com/2016/10/ai-changing-market-computer-chips/


Pictures:
Google TPU v3: https://cloud.google.com/tpu/


Fragen Google Biased Paper selber geschrieben?
Sources von Sources verwenden?


