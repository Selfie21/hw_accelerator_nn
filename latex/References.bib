%1 FPGAs
@article{historyfpgas,
	title={Deep learning on fpgas: Past, present, and future},
	author={Lacey, Griffin and Taylor, Graham W and Areibi, Shawki},
	journal={arXiv preprint arXiv:1602.04283},
	year={2016}
}

%2 future internet
@article{capra2020updated,
	title={An updated survey of efficient hardware architectures for accelerating deep convolutional neural networks},
	author={Capra, Maurizio and Bussolino, Beatrice and Marchisio, Alberto and Shafique, Muhammad and Masera, Guido and Martina, Maurizio},
	journal={Future Internet},
	volume={12},
	number={7},
	pages={113},
	year={2020},
	publisher={Multidisciplinary Digital Publishing Institute}
}

%3 TPU
@inproceedings{jouppi2017datacenter,
	title={In-datacenter performance analysis of a tensor processing unit},
	author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and others},
	booktitle={Proceedings of the 44th annual international symposium on computer architecture},
	pages={1--12},
	year={2017}
}

%4 Microsoft FPGAs
@article{ovtcharov2015accelerating,
	title={Accelerating deep convolutional neural networks using specialized hardware},
	author={Ovtcharov, Kalin and Ruwase, Olatunji and Kim, Joo-Young and Fowers, Jeremy and Strauss, Karin and Chung, Eric S},
	journal={Microsoft Research Whitepaper},
	volume={2},
	number={11},
	pages={1--4},
	year={2015}
}

%5 Survey on RNN Overall
@inproceedings{nurvitadhi2016accelerating,
	title={Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC},
	author={Nurvitadhi, Eriko and Sim, Jaewoong and Sheffield, David and Mishra, Asit and Krishnan, Srivatsan and Marr, Debbie},
	booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)},
	pages={1--4},
	year={2016},
	organization={IEEE}
}

%7 Survey technical
@article{talib2020systematic,
	title={A systematic literature review on hardware implementation of artificial intelligence algorithms},
	author={Talib, Manar Abu and Majzoub, Sohaib and Nasir, Qassim and Jamal, Dina},
	journal={The Journal of Supercomputing},
	pages={1--42},
	year={2020},
	publisher={Springer}
}

%8 Survey technical indian
@article{jawandhiya2018hardware,
	title={Hardware design for machine learning},
	author={Jawandhiya, Pooja},
	journal={International Journal of Artificial Intelligence and Applications (IJAIA)},
	volume={9},
	number={1},
	pages={63--84},
	year={2018}
}


%usages Neural Network
@inproceedings{speech_recognition1,
	title={New types of deep neural network learning for speech recognition and related applications: An overview},
	author={Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
	booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
	pages={8599--8603},
	year={2013},
	organization={IEEE}
}

%Basics
@misc{nn_basics,
	author = {Eda Kavlakoglu},
	title = {\href{https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks}{AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?}},
	journal = {IBM Blog},
	year = {2020},
	note = "(accessed 3 February 2021)"
}

%Large Layer Amount
@inproceedings{densely_network,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

%Intel Processor used for ML
@misc{intelnn,
	author = {Sunny L Gogar},
	title = {\href{https://software.intel.com/content/www/us/en/develop/articles/bigdl-scale-out-deep-learning-on-apache-spark-cluster.html}{BigDL – Scale-out Deep Learning on Apache Spark* Cluster }},
	journal = {Intel Blog},
	year = {2017},
	note = "(accessed 3 February 2021)"
}

%Most used GPU
@misc{mostusedgpu,
	author = {Clayton Cotterell},
	title = {\href{https://www.wired.com/2016/10/ai-changing-market-computer-chips/}{How AI Is Shaking Up the Chip Market}},
	journal = {Wired Blog},
	year = {2016},
	note = "(accessed 4 February 2021)"
}

%Nvidia V100
@misc{nvidiav100,
	title = {\href{https://images.nvidia.com/content/technologies/volta/pdf/437317-Volta-V100-DS-NV-US-WEB.pdf}{Nvidia v100 Datasheet}},
	journal = {Nvidia Blog},
	year = {2017},
	note = "(accessed 4 February 2021)"
}

%Tensor Cores
@misc{tensorcores,
	author = {Mark Harris},
	title = {\href{https://developer.nvidia.com/blog/cuda-9-features-revealed/}{CUDA 9 Features Revealed: Volta, Cooperative Groups and More}},
	journal = {Nvidia Blog},
	year = {2017},
	note = "(accessed 4 February 2021)"
}

%Intel Picture Comparison CPU GPU
@misc{intelpic_comparison,
	title = {\href{https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png}{Comparison between a CPU and GPU}},
	year = {2021},
	note = {(accessed 4 February 2021)},
}

%Microsoft 2 Times Performance
@inproceedings{putnam2014reconfigurable,
	title={A reconfigurable fabric for accelerating large-scale datacenter services},
	author={Putnam, Andrew and Caulfield, Adrian M and Chung, Eric S and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and others},
	booktitle={2014 ACM/IEEE 41st International Symposium on Computer Architecture (ISCA)},
	pages={13--24},
	year={2014},
	organization={IEEE}
}


%Majors FPGA
@misc{majorfpga,
	author = {Paul Dillien},
	title = {\href{https://www.eetimes.com/and-the-winner-of-best-fpga-of-2016-is/}{And the Winner of Best FPGA of 2016 is…}},
	journal = {EE Times},
	year = {03.06.2017},
	note = "(accessed 12 February 2021)"
}

%Limited numerical precision
@inproceedings{gupta2015deep,
	title={Deep learning with limited numerical precision},
	author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
	booktitle={International conference on machine learning},
	pages={1737--1746},
	year={2015},
	organization={PMLR}
}


%Examples of similiar FPGA approaches
@inproceedings{qiu2016going,
	title={Going deeper with embedded fpga platform for convolutional neural network},
	author={Qiu, Jiantao and Wang, Jie and Yao, Song and Guo, Kaiyuan and Li, Boxun and Zhou, Erjin and Yu, Jincheng and Tang, Tianqi and Xu, Ningyi and Song, Sen and others},
	booktitle={Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	pages={26--35},
	year={2016}
}

@article{wang2016dlau,
	title={DLAU: A scalable deep learning accelerator unit on FPGA},
	author={Wang, Chao and Gong, Lei and Yu, Qi and Li, Xi and Xie, Yuan and Zhou, Xuehai},
	journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	volume={36},
	number={3},
	pages={513--517},
	year={2016},
	publisher={IEEE}
}

% Limited numerical precision
@article{rodriguez2018lower,
	title={Lower numerical precision deep learning inference and training},
	author={Rodriguez, Andres and Segal, Eden and Meiri, Etay and Fomenko, Evarist and Kim, Y Jim and Shen, Haihao and Ziv, Barukh},
	journal={Intel White Paper},
	volume={3},
	pages={1--19},
	year={2018}
}

%Second Version TPU
@misc{secondversiontpu,
	author={Jeff Dean, Urs Hölzle},
	title = {\href{https://blog.google/products/google-cloud/google-cloud-offer-tpus-machine-learning/}{Build and train machine learning models on our new Google Cloud TPUs}},
	journal = {Google Blog},
	year = {17.05.2017},
	note = "(accessed 14 February 2021)"
}

%Third Version TPU
@misc{thirdversiontpu,
	title = {\href{https://cloud.google.com/tpu/docs/system-architecture#pod}{Cloud TPU System Architecture}},
	journal = {Google Blog},
	year = {08.02.2021},
	note = "(accessed 14 February 2021)"
}

%Fourth Version TPU
@misc{fourthversiontpu,
	author = {Naveen Kumar},
	title = {\href{https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer}{Google breaks AI performance records in MLPerf with world's fastest training supercomputer}},
	journal = {Google Blog},
	year = {29.06.2021},
	note = "(accessed 14 February 2021)"
}

%BenchQQ_Benchmarking
@inproceedings{chen2012benchnn,
	title={Benchnn: On the broad potential application scope of hardware neural network accelerators},
	author={Chen, Tianshi and Chen, Yunji and Duranton, Marc and Guo, Qi and Hashmi, Atif and Lipasti, Mikko and Nere, Andrew and Qiu, Shi and Sebag, Michele and Temam, Olivier},
	booktitle={2012 IEEE International Symposium on Workload Characterization (IISWC)},
	pages={36--45},
	year={2012},
	organization={IEEE}
}

%TBD_Benchmarking
@inproceedings{zhu2018benchmarking,
	title={Benchmarking and analyzing deep neural network training},
	author={Zhu, Hongyu and Akrout, Mohamed and Zheng, Bojian and Pelegris, Andrew and Jayarajan, Anand and Phanishayee, Amar and Schroeder, Bianca and Pekhimenko, Gennady},
	booktitle={2018 IEEE International Symposium on Workload Characterization (IISWC)},
	pages={88--100},
	year={2018},
	organization={IEEE}
}

%Quti_Benchmark gucci
@article{blott2019qutibench,
	title={QuTiBench: Benchmarking neural networks on heterogeneous hardware},
	author={Blott, Michaela and Halder, Lisa and Leeser, Miriam and Doyle, Linda},
	journal={ACM Journal on Emerging Technologies in Computing Systems (JETC)},
	volume={15},
	number={4},
	pages={1--38},
	year={2019},
	publisher={ACM New York, NY, USA}
}

%GPU Benchmarking
@incollection{dong2017dnnmark,
	title={Dnnmark: A deep neural network benchmark suite for gpus},
	author={Dong, Shi and Kaeli, David},
	booktitle={Proceedings of the General Purpose GPUs},
	pages={63--72},
	year={2017},
	publisher={ACM}
}

%MLPerf
@article{mattson2020mlperf,
	title={MLPerf: An industry standard benchmark suite for machine learning performance},
	author={Mattson, Peter and Reddi, Vijay Janapa and Cheng, Christine and Coleman, Cody and Diamos, Greg and Kanter, David and Micikevicius, Paulius and Patterson, David and Schmuelling, Guenther and Tang, Hanlin and others},
	journal={IEEE Micro},
	volume={40},
	number={2},
	pages={8--16},
	year={2020},
	publisher={IEEE}
}

%MLPerf Results
@misc{mlperfresultshpc,
	author={John Russell},
	title = {\href{https://www.hpcwire.com/2020/10/22/nvidia-dominates-again-latest-mlperf-inference-results/}{Nvidia Dominates (Again) Latest MLPerf Inference Results}},
	journal = {HPC Wire},
	year = {22.10.2020},
	note = "(accessed 17 February 2021)"
}

%MLPerf Traning Results v7
@misc{mlperfresults,
	title = {\href{https://mlperf.org/training-results-0-7}{MLPerf Training v0.7 Results}},
	journal = {MLPerf},
	year = {29.07.2020},
	note = "(accessed 17 February 2021)"
}


%MLPerf NVIDIA
@misc{mlperfresultsnvidia,
	author = {Paresh Kharya},
	title = {\href{https://blogs.nvidia.com/blog/2020/10/21/inference-mlperf-benchmarks/}{NVIDIA Inference Performance Surges as AI Use Crosses Tipping Point}},
	journal = {NVIDIA Blog},
	year = {21.10.2020},
	note = "(accessed 17 February 2021)"
}

%IOT General
@article{sze2017efficient,
	title={Efficient processing of deep neural networks: A tutorial and survey},
	author={Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S},
	journal={Proceedings of the IEEE},
	volume={105},
	number={12},
	pages={2295--2329},
	year={2017},
	publisher={Ieee}
}

%GO
@article{chouard2016go,
	title={The Go Files: AI computer wraps up 4-1 victory against human champion},
	author={Chouard, Tanguy},
	journal={Nature News},
	year={2016}
}

%Edge
@article{wang2020convergence,
	title={Convergence of edge computing and deep learning: A comprehensive survey},
	author={Wang, Xiaofei and Han, Yiwen and Leung, Victor CM and Niyato, Dusit and Yan, Xueqiang and Chen, Xu},
	journal={IEEE Communications Surveys \& Tutorials},
	volume={22},
	number={2},
	pages={869--904},
	year={2020},
	publisher={IEEE}
}

%EdgeCPU
@inproceedings{chen2019exploring,
	title={Exploring the capabilities of mobile devices in supporting deep learning},
	author={Chen, Yitao and Biookaghazadeh, Saman and Zhao, Ming},
	booktitle={Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
	pages={127--138},
	year={2019}
}

%EdgeFPGA
@inproceedings{jiang2018accelerating,
	title={Accelerating mobile applications at the network edge with software-programmable FPGAs},
	author={Jiang, Shuang and He, Dong and Yang, Chenxi and Xu, Chenren and Luo, Guojie and Chen, Yang and Liu, Yunlu and Jiang, Jiangwei},
	booktitle={IEEE INFOCOM 2018-IEEE Conference on Computer Communications},
	pages={55--62},
	year={2018},
	organization={IEEE}
}

%Siemens NPU
@misc{siemensnpu,
	title = {\href{https://new.siemens.com/global/en/products/automation/systems/industrial/plc/simatic-s7-1500/simatic-s7-1500-tm-npu.html}SIMATIC S7-1500 TM NPU}},
	journal = {Siemens},
	year = {01.04.2020},
	note = "(accessed 17 February 2021)"
}

%Apple NPU
@misc{applenpu,
	author = {Harsh Chandra},
	title = {\href{https://heartbeat.fritz.ai/hardware-acceleration-for-machine-learning-on-apple-and-android-f3e6ca85bda6}{Hardware acceleration for machine learning on Apple and Android devices}},
	journal = {Heartbeat Fritz AI},
	year = {08.10.2020},
	note = "(accessed 17 February 2021)"
}

%layer increase
@inproceedings{szegedy2015going,
	title={Going deeper with convolutions},
	author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1--9},
	year={2015}
}

%
@inproceedings{zhang2018ffs,
	title={FFS-VA: A fast filtering system for large-scale video analytics},
	author={Zhang, Chen and Cao, Qiang and Jiang, Hong and Zhang, Wenhui and Li, Jingjun and Yao, Jie},
	booktitle={Proceedings of the 47th International Conference on Parallel Processing},
	pages={1--10},
	year={2018}
}

%NVIDIA GPU
@misc{nvidia100,
	title = {\href{https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf}{NVIDIA A100 Tensor Core GPU Architecture}},
	journal = {Heartbeat Fritz AI},
	year = {08.10.2020},
	note = "(accessed 19 February 2021)"
}

%Siemens Picture
@misc{siemensnpu_pic,
	title = {\href{https://press.siemens.com/global/de/pressemitteilung/kuenstliche-intelligenz-fuer-die-simatic}{Künstliche Intelligenz für die Simatic, Siemens Blog}},
	year = {2021},
	note = {(accessed 14 March 2021)},
}

https://press.siemens.com/global/de/pressemitteilung/kuenstliche-intelligenz-fuer-die-simatic