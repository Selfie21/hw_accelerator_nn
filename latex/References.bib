%1 FPGAs
@article{historyfpgas,
	title={Deep learning on fpgas: Past, present, and future},
	author={Lacey, Griffin and Taylor, Graham W and Areibi, Shawki},
	journal={arXiv preprint arXiv:1602.04283},
	year={2016}
}

%2 future internet
@article{capra2020updated,
	title={An updated survey of efficient hardware architectures for accelerating deep convolutional neural networks},
	author={Capra, Maurizio and Bussolino, Beatrice and Marchisio, Alberto and Shafique, Muhammad and Masera, Guido and Martina, Maurizio},
	journal={Future Internet},
	volume={12},
	number={7},
	pages={113},
	year={2020},
	publisher={Multidisciplinary Digital Publishing Institute}
}

%3 TPU
@inproceedings{jouppi2017datacenter,
	title={In-datacenter performance analysis of a tensor processing unit},
	author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and others},
	booktitle={Proceedings of the 44th annual international symposium on computer architecture},
	pages={1--12},
	year={2017}
}

%4 Microsoft FPGAs
@article{ovtcharov2015accelerating,
	title={Accelerating deep convolutional neural networks using specialized hardware},
	author={Ovtcharov, Kalin and Ruwase, Olatunji and Kim, Joo-Young and Fowers, Jeremy and Strauss, Karin and Chung, Eric S},
	journal={Microsoft Research Whitepaper},
	volume={2},
	number={11},
	pages={1--4},
	year={2015}
}

%5 Survey on RNN Overall
@inproceedings{nurvitadhi2016accelerating,
	title={Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC},
	author={Nurvitadhi, Eriko and Sim, Jaewoong and Sheffield, David and Mishra, Asit and Krishnan, Srivatsan and Marr, Debbie},
	booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)},
	pages={1--4},
	year={2016},
	organization={IEEE}
}

%6 Survey Indian okay
@article{jangamreddy2019survey,
	title={A Survey on Specialised Hardware for Machine Learning},
	author={Jangamreddy, Nikhil},
	year={2019}
}

%7 Survey technical
@article{talib2020systematic,
	title={A systematic literature review on hardware implementation of artificial intelligence algorithms},
	author={Talib, Manar Abu and Majzoub, Sohaib and Nasir, Qassim and Jamal, Dina},
	journal={The Journal of Supercomputing},
	pages={1--42},
	year={2020},
	publisher={Springer}
}

%8 Survey technical
@article{jawandhiya2018hardware,
	title={Hardware design for machine learning},
	author={Jawandhiya, Pooja},
	journal={International Journal of Artificial Intelligence and Applications (IJAIA)},
	volume={9},
	number={1},
	pages={63--84},
	year={2018}
}


%usages Neural Network
@inproceedings{speech_recognition1,
	title={New types of deep neural network learning for speech recognition and related applications: An overview},
	author={Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
	booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
	pages={8599--8603},
	year={2013},
	organization={IEEE}
}

%Basics
@misc{nn_basics,
	author = {Eda Kavlakoglu},
	title = {\href{https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks}{AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?}},
	journal = {IBM Blog},
	year = {2020},
	note = "(accessed 3 February 2021)"
}

%Large Layer Amount
@inproceedings{densely_network,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

%Intel Processor used for ML
@misc{intelnn,
	author = {Sunny L Gogar},
	title = {\href{https://software.intel.com/content/www/us/en/develop/articles/bigdl-scale-out-deep-learning-on-apache-spark-cluster.html}{BigDL – Scale-out Deep Learning on Apache Spark* Cluster }},
	journal = {Intel Blog},
	year = {2017},
	note = "(accessed 3 February 2021)"
}

%Most used GPU
@misc{mostusedgpu,
	author = {Clayton Cotterell},
	title = {\href{https://www.wired.com/2016/10/ai-changing-market-computer-chips/}{How AI Is Shaking Up the Chip Market}},
	journal = {Wired Blog},
	year = {2016},
	note = "(accessed 4 February 2021)"
}

%Nvidia V100
@misc{nvidiav100,
	title = {\href{https://images.nvidia.com/content/technologies/volta/pdf/437317-Volta-V100-DS-NV-US-WEB.pdf}{Nvidia v100 Datasheet}},
	journal = {Nvidia Blog},
	year = {2017},
	note = "(accessed 4 February 2021)"
}

%Tensor Cores
@misc{tensorcores,
	author = {Mark Harris},
	title = {\href{https://developer.nvidia.com/blog/cuda-9-features-revealed/}{CUDA 9 Features Revealed: Volta, Cooperative Groups and More}},
	journal = {Nvidia Blog},
	year = {2017},
	note = "(accessed 4 February 2021)"
}

%Intel Picture Comparison CPU GPU
@misc{intelpic_comparison,
	title = {\href{https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png}{Comparison between a CPU and GPU}},
	year = {2021},
	note = {(accessed 4 February 2021)},
}


