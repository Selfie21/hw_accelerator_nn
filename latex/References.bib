%1 FPGAs
@article{historyfpgas,
	title={Deep learning on fpgas: Past, present, and future},
	author={Lacey, Griffin and Taylor, Graham W and Areibi, Shawki},
	journal={arXiv preprint arXiv:1602.04283},
	year={2016}
}

%2 future internet
@article{capra2020updated,
	title={An updated survey of efficient hardware architectures for accelerating deep convolutional neural networks},
	author={Capra, Maurizio and Bussolino, Beatrice and Marchisio, Alberto and Shafique, Muhammad and Masera, Guido and Martina, Maurizio},
	journal={Future Internet},
	volume={12},
	number={7},
	pages={113},
	year={2020},
	publisher={Multidisciplinary Digital Publishing Institute}
}

%3 TPU
@inproceedings{jouppi2017datacenter,
	title={In-datacenter performance analysis of a tensor processing unit},
	author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and others},
	booktitle={Proceedings of the 44th annual international symposium on computer architecture},
	pages={1--12},
	year={2017}
}

%4 Microsoft FPGAs
@article{ovtcharov2015accelerating,
	title={Accelerating deep convolutional neural networks using specialized hardware},
	author={Ovtcharov, Kalin and Ruwase, Olatunji and Kim, Joo-Young and Fowers, Jeremy and Strauss, Karin and Chung, Eric S},
	journal={Microsoft Research Whitepaper},
	volume={2},
	number={11},
	pages={1--4},
	year={2015}
}

%5 Survey on RNN Overall
@inproceedings{nurvitadhi2016accelerating,
	title={Accelerating recurrent neural networks in analytics servers: Comparison of FPGA, CPU, GPU, and ASIC},
	author={Nurvitadhi, Eriko and Sim, Jaewoong and Sheffield, David and Mishra, Asit and Krishnan, Srivatsan and Marr, Debbie},
	booktitle={2016 26th International Conference on Field Programmable Logic and Applications (FPL)},
	pages={1--4},
	year={2016},
	organization={IEEE}
}

%6 Survey Indian okay
@article{jangamreddy2019survey,
	title={A Survey on Specialised Hardware for Machine Learning},
	author={Jangamreddy, Nikhil},
	year={2019}
}

%7 Survey technical
@article{talib2020systematic,
	title={A systematic literature review on hardware implementation of artificial intelligence algorithms},
	author={Talib, Manar Abu and Majzoub, Sohaib and Nasir, Qassim and Jamal, Dina},
	journal={The Journal of Supercomputing},
	pages={1--42},
	year={2020},
	publisher={Springer}
}

%8 Survey technical
@article{jawandhiya2018hardware,
	title={Hardware design for machine learning},
	author={Jawandhiya, Pooja},
	journal={International Journal of Artificial Intelligence and Applications (IJAIA)},
	volume={9},
	number={1},
	pages={63--84},
	year={2018}
}


%usages Neural Network
@inproceedings{speech_recognition1,
	title={New types of deep neural network learning for speech recognition and related applications: An overview},
	author={Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
	booktitle={2013 IEEE international conference on acoustics, speech and signal processing},
	pages={8599--8603},
	year={2013},
	organization={IEEE}
}

%Basics
@misc{nn_basics,
	author = {Eda Kavlakoglu},
	title = {\href{https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks}{AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?}},
	journal = {IBM Blog},
	year = {2020},
	note = "(accessed 3 February 2021)"
}

%Large Layer Amount
@inproceedings{densely_network,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

%Intel Processor used for ML
@misc{intelnn,
	author = {Sunny L Gogar},
	title = {\href{https://software.intel.com/content/www/us/en/develop/articles/bigdl-scale-out-deep-learning-on-apache-spark-cluster.html}{BigDL – Scale-out Deep Learning on Apache Spark* Cluster }},
	journal = {Intel Blog},
	year = {2017},
	note = "(accessed 3 February 2021)"
}

%Most used GPU
@misc{mostusedgpu,
	author = {Clayton Cotterell},
	title = {\href{https://www.wired.com/2016/10/ai-changing-market-computer-chips/}{How AI Is Shaking Up the Chip Market}},
	journal = {Wired Blog},
	year = {2016},
	note = "(accessed 4 February 2021)"
}

%Nvidia V100
@misc{nvidiav100,
	title = {\href{https://images.nvidia.com/content/technologies/volta/pdf/437317-Volta-V100-DS-NV-US-WEB.pdf}{Nvidia v100 Datasheet}},
	journal = {Nvidia Blog},
	year = {2017},
	note = "(accessed 4 February 2021)"
}

%Tensor Cores
@misc{tensorcores,
	author = {Mark Harris},
	title = {\href{https://developer.nvidia.com/blog/cuda-9-features-revealed/}{CUDA 9 Features Revealed: Volta, Cooperative Groups and More}},
	journal = {Nvidia Blog},
	year = {2017},
	note = "(accessed 4 February 2021)"
}

%Intel Picture Comparison CPU GPU
@misc{intelpic_comparison,
	title = {\href{https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png}{Comparison between a CPU and GPU}},
	year = {2021},
	note = {(accessed 4 February 2021)},
}

%Microsoft 2 Times Performance
@inproceedings{putnam2014reconfigurable,
	title={A reconfigurable fabric for accelerating large-scale datacenter services},
	author={Putnam, Andrew and Caulfield, Adrian M and Chung, Eric S and Chiou, Derek and Constantinides, Kypros and Demme, John and Esmaeilzadeh, Hadi and Fowers, Jeremy and Gopal, Gopi Prashanth and Gray, Jan and others},
	booktitle={2014 ACM/IEEE 41st International Symposium on Computer Architecture (ISCA)},
	pages={13--24},
	year={2014},
	organization={IEEE}
}


%Majors FPGA
@misc{majorfpga,
	author = {Paul Dillien},
	title = {\href{https://www.eetimes.com/and-the-winner-of-best-fpga-of-2016-is/}{And the Winner of Best FPGA of 2016 is…}},
	journal = {EE Times},
	year = {03.06.2017},
	note = "(accessed 12 February 2021)"
}

%Limited numerical precision
@inproceedings{gupta2015deep,
	title={Deep learning with limited numerical precision},
	author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
	booktitle={International conference on machine learning},
	pages={1737--1746},
	year={2015},
	organization={PMLR}
}


%Examples of similiar FPGA approaches
@inproceedings{qiu2016going,
	title={Going deeper with embedded fpga platform for convolutional neural network},
	author={Qiu, Jiantao and Wang, Jie and Yao, Song and Guo, Kaiyuan and Li, Boxun and Zhou, Erjin and Yu, Jincheng and Tang, Tianqi and Xu, Ningyi and Song, Sen and others},
	booktitle={Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	pages={26--35},
	year={2016}
}

@article{wang2016dlau,
	title={DLAU: A scalable deep learning accelerator unit on FPGA},
	author={Wang, Chao and Gong, Lei and Yu, Qi and Li, Xi and Xie, Yuan and Zhou, Xuehai},
	journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	volume={36},
	number={3},
	pages={513--517},
	year={2016},
	publisher={IEEE}
}





